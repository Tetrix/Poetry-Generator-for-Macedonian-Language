{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/data.txt', 'r') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = tuple(set(text))\n",
    "int2char = dict(enumerate(chars))\n",
    "char2int = {ch: ii for ii, ch in int2char.items()}\n",
    "\n",
    "encoded = np.array([char2int[ch] for ch in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoder(arr, n_labels):\n",
    "    one_hot = np.zeros((np.multiply(*arr.shape), n_labels), dtype=np.float32)\n",
    "    one_hot[np.arange(one_hot.shape[0]), arr.flatten()] = 1.\n",
    "    one_hot = one_hot.reshape((*arr.shape, n_labels))\n",
    "    \n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):  \n",
    "    def __init__(self, tokens, hidden_size, n_layers, dropout_prob):\n",
    "        super().__init__()\n",
    "        self.dropout_prob = dropout_prob\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.chars = tokens\n",
    "        self.int2char = dict(enumerate(self.chars))\n",
    "        self.char2int = {ch: ii for ii, ch in self.int2char.items()}\n",
    "        \n",
    "        self.lstm = nn.LSTM(len(self.chars), \n",
    "                            self.hidden_size, \n",
    "                            n_layers, \n",
    "                            dropout=dropout_prob,\n",
    "                            bidirectional=False,\n",
    "                            batch_first=True\n",
    "                           )\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.lin = nn.Linear(self.hidden_size, len(self.chars))\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        r_output, hidden = self.lstm(x, hidden)\n",
    "        out = self.dropout(r_output)\n",
    "        out = out.contiguous().view(-1, self.hidden_size)\n",
    "        out = self.lin(out)\n",
    "        return out, hidden\n",
    "        \n",
    "\n",
    "    def init_hidden(self, batch_size=1, device=device):\n",
    "        return (torch.zeros(self.n_layers, batch_size, self.hidden_size, device=device), \n",
    "                torch.zeros(self.n_layers, batch_size, self.hidden_size, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(arr, batch_size, seq_length):\n",
    "    batch_size_total = batch_size * seq_length\n",
    "    n_batches = len(arr)//batch_size_total\n",
    "    arr = arr[:n_batches * batch_size_total]\n",
    "    arr = arr.reshape((batch_size, -1))\n",
    "    \n",
    "    for n in range(0, arr.shape[1], seq_length):\n",
    "        x = arr[:, n:n+seq_length]\n",
    "        y = np.zeros_like(x)\n",
    "        try:\n",
    "            y[:, :-1], y[:, -1] = x[:, 1:], arr[:, n+seq_length]\n",
    "        except IndexError:\n",
    "            \"Wrong index\"\n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, epochs, batch_size, seq_length, lr, criterion, optimizer, val_frac, print_every):\n",
    "    train_loss = []\n",
    "    validation_loss = []\n",
    "    epoch_viz = []\n",
    "    \n",
    "    val_idx = int(len(data) * (1 - val_frac))\n",
    "    data, val_data = data[:val_idx], data[val_idx:]\n",
    "\n",
    "    counter = 0\n",
    "    n_chars = len(model.chars)\n",
    "    for epoch in range(epochs):\n",
    "        hidden = model.init_hidden(batch_size)      \n",
    "        for x, y in get_batches(data, batch_size, seq_length):\n",
    "            counter += 1\n",
    "\n",
    "            x = one_hot_encoder(x, n_chars)\n",
    "            \n",
    "            inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            hidden = tuple([each.data for each in hidden])\n",
    "            \n",
    "            model.zero_grad()\n",
    "            \n",
    "            output, hidden = model(inputs, hidden)\n",
    "                    \n",
    "            loss = criterion(output, targets.view(batch_size * seq_length).long())\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            \n",
    "            # validation\n",
    "            if counter % print_every == 0:\n",
    "                val_hidden = model.init_hidden(batch_size)\n",
    "                val_losses = []\n",
    "                model.eval()\n",
    "                for x, y in get_batches(val_data, batch_size, seq_length):\n",
    "                    x = one_hot_encoder(x, n_chars)\n",
    "                    x, y = torch.from_numpy(x), torch.from_numpy(y)\n",
    "                    val_hidden = tuple([each.data for each in val_hidden])\n",
    "                    \n",
    "                    inputs, targets = x, y\n",
    "                    inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "                    output, val_hidden = model(inputs, val_hidden)\n",
    "                    val_loss = criterion(output, targets.view(batch_size * seq_length).long())\n",
    "                \n",
    "                    val_losses.append(val_loss.item())\n",
    "                \n",
    "                model.train()\n",
    "                \n",
    "                print(\"Epoch: {}/{}...\".format(epoch + 1, epochs),\n",
    "                      \"Step: {}...\".format(counter),\n",
    "                      \"Loss: {:.4f}...\".format(loss.item()),\n",
    "                      \"Val Loss: {:.4f}\".format(np.mean(val_losses)))\n",
    "                \n",
    "                train_loss.append(loss.item())\n",
    "                validation_loss.append(np.mean(val_losses))\n",
    "                epoch_viz.append(epoch+1)\n",
    "    return train_loss, validation_loss, epoch_viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (lstm): LSTM(186, 768, num_layers=3, batch_first=True, dropout=0.5)\n",
       "  (dropout): Dropout(p=0.5)\n",
       "  (lin): Linear(in_features=768, out_features=186, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_size = 768\n",
    "n_layers = 3\n",
    "dropout_prob = 0.5\n",
    "\n",
    "model = RNN(tokens=chars, hidden_size=hidden_size, n_layers=n_layers, dropout_prob=dropout_prob).to(device)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, amsgrad=True)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (lstm): LSTM(186, 768, num_layers=3, batch_first=True, dropout=0.5)\n",
       "  (dropout): Dropout(p=0.5)\n",
       "  (lin): Linear(in_features=768, out_features=186, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model\n",
    "batch_size = 64\n",
    "seq_length = 150\n",
    "n_epochs = 40\n",
    "print_every = 100\n",
    "val_frac = 0.1\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if skip_training == False:\n",
    "    train_loss, validation_loss, epoch_viz = train(model=model, \n",
    "                                                  data=encoded, \n",
    "                                                  epochs=n_epochs, \n",
    "                                                  batch_size=batch_size, \n",
    "                                                  seq_length=seq_length, \n",
    "                                                  lr=lr, \n",
    "                                                  criterion=criterion, \n",
    "                                                  optimizer=optimizer, \n",
    "                                                  print_every=print_every, \n",
    "                                                  val_frac=val_frac,\n",
    "                                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if skip_training == False:\n",
    "    torch.save(model, 'model')\n",
    "else:\n",
    "    model = torch.load('model')\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if skip_training == False:\n",
    "    plt.plot(epoch_viz, train_loss)\n",
    "    plt.plot(epoch_viz, validation_loss)\n",
    "    plt.legend(['train_loss', 'validation_loss'])\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.title('Training Loss')\n",
    "    plt.savefig('images/loss.png', dpi=400)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a method to generate the next character\n",
    "def predict(model, char, hidden=None, top_k=None):\n",
    "        ''' Given a character, predict the next character.\n",
    "            Returns the predicted character and the hidden state.\n",
    "        '''\n",
    "        \n",
    "        # tensor inputs\n",
    "        x = np.array([[model.char2int[char]]])\n",
    "        x = one_hot_encoder(x, len(model.chars))\n",
    "        \n",
    "        inputs = torch.from_numpy(x)\n",
    "        inputs = inputs.to(device)\n",
    "        \n",
    "        hidden = tuple([each.data for each in hidden])\n",
    "        output, hidden = model(inputs, hidden)\n",
    "\n",
    "        p = F.softmax(output, dim=1).data\n",
    "        p = p.cpu()\n",
    "        \n",
    "        if top_k is None:\n",
    "            top_ch = np.arange(len(model.chars))\n",
    "        else:\n",
    "            p, top_ch = p.topk(top_k)\n",
    "            top_ch = top_ch.numpy().squeeze()\n",
    "        \n",
    "        p = p.numpy().squeeze()\n",
    "        char = np.random.choice(top_ch, p=p / p.sum())\n",
    "        return model.int2char[char], hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(model, size, prime, top_k=None):\n",
    "    model.to(device)   \n",
    "    model.eval()\n",
    "    chars = [ch for ch in prime]\n",
    "    hidden = model.init_hidden(1)\n",
    "    for ch in prime:\n",
    "        char, hidden = predict(model, ch, hidden, top_k=top_k)\n",
    "\n",
    "    chars.append(char)\n",
    "\n",
    "    for ii in range(size):\n",
    "        char, hidden = predict(model, chars[-1], hidden, top_k=top_k)\n",
    "        chars.append(char)\n",
    "    \n",
    "    text = ''.join(chars)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = sample(model, 1000, prime=' ', top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove punctuation\n",
    "def remove_punctuation(text):\n",
    "    words_clean = []\n",
    "    for word in text.split():\n",
    "        words_clean.append(re.sub(r'[^\\w\\s]', '', word))\n",
    "    return words_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text = remove_punctuation(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(clean_text):\n",
    "    correct_words = 0\n",
    "    incorrect_words = 0\n",
    "    \n",
    "    with open('data/unique_words.txt', 'r') as f:\n",
    "        vocab = f.read().splitlines()\n",
    "        \n",
    "    for word in clean_text:\n",
    "        if word in vocab:\n",
    "            correct_words += 1\n",
    "        else:\n",
    "            incorrect_words += 1\n",
    "    \n",
    "    accuracy = correct_words / (correct_words + incorrect_words)\n",
    "    return accuracy, correct_words, incorrect_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy, correct_words, incorrect_words = evaluate(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of correct words is: 163, number of incorrect words is 13, accuracy is: 0.9261363636363636\n"
     ]
    }
   ],
   "source": [
    "print('Number of correct words is: {}, number of incorrect words is {}, accuracy is: {}'.format(correct_words, incorrect_words, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " на неговите денови\n",
      "кај неговите солзи врзани со приказните\n",
      "\n",
      "Ми го однесуваш танцот на месата, \n",
      "на тебе само се влажам,\n",
      "на паризак низ странците стари,\n",
      "ако треперам и насмевка,\n",
      "се смееш, а ти напишав сила.\n",
      "\n",
      "Колку само погледи се нема\n",
      "и тие други сетила\n",
      "на нас со тебе,\n",
      "а неможам да те издавам\n",
      "сите мои среќни магии\n",
      "крвава нозе, со тешки патеки,\n",
      "и така добри,\n",
      "не знаеме,\n",
      "кога ќе ги пробам доволно срце да спомнат,\n",
      "со патиштата на небото\n",
      "на твојот пролет\n",
      "не ме пронаоѓаат.\n",
      "\n",
      "Неколку сини коски\n",
      "не може да ме зброни\n",
      "врз сите свои,\n",
      "кога сите се насмевка виднаат,\n",
      "ние сонувам.\n",
      "\n",
      "Стариот портен пола пламен.\n",
      "\n",
      "Сите се сеќаваат, ние,\n",
      "преку пролетта со топли прегратки,\n",
      "низ купето молитви,\n",
      "подадени прекрасни солзи,\n",
      "на твојот гроб и магија.\n",
      "\n",
      "Некако со најслепин клуп,\n",
      "со песочи в небиднина светеа.\n",
      "Не знам како потрешна стави,\n",
      "само низ тој пријател по мир,\n",
      "но ниедна мисла си, \n",
      "на неговото срце, \n",
      "се раѓаме со сила да помине,\n",
      "насмевка и присуство, сакав,\n",
      "дур не се пронајдам,\n",
      "никој не ми се прости на срцево!\n",
      "\n",
      "Про\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
